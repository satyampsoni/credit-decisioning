{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#00000\"> Credit Decisioning Model</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler \n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Load the dataset\n",
    "data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#inspect the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"The shape =\", data.shape)\n",
    "\n",
    "# Dataset dimensions and statistics\n",
    "num_rows, num_cols = loan_data.shape\n",
    "num_features = num_cols - 1\n",
    "total_data = num_rows * num_cols\n",
    "\n",
    "print(\"No. of rows:\", num_rows)\n",
    "print(\"No. of columns:\", num_cols)\n",
    "print(\"No of features:\", num_features)\n",
    "print(\"Total data:\",total_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(loan_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#categorical data\n",
    "data.describe(include=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Numerical data\n",
    "loan_data.describe().T.round(2) #T.round(2) rounds up the data upto two decimals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description**\n",
    "\n",
    "* **count:** The number of non-null values in the dataset for a given variable.\n",
    "* **mean:** The average value, calculated by summing all values and dividing by the count.\n",
    "* **Standard Deviation (std):** Measures how spread out the data is around the mean. A higher standard deviation indicates greater variability.\n",
    "* **min:** The smallest value present in the dataset for that variable.\n",
    "* **25%:** The first quartile. 25% of the data falls below this value.\n",
    "* **50%:** The median or second quartile. 50% of the data falls below this value.\n",
    "* **75%:** The third quartile. 75% of the data falls below this value.\n",
    "* **max:** The largest value present in the dataset for that variable.\n",
    "\n",
    "Now, we have done inspecting the data, let's move forward with the next step exlporing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploratory Data Analysis**, we'll be visualising the data here to understand more in depth about the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualising the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Calculate the average income\n",
    "mean_income = data['ApplicantIncome'].mean()\n",
    "print(\"Mean Income:\", mean_income)\n",
    "\n",
    "# Count applicants above and below mean income\n",
    "high_income_count = (data['ApplicantIncome'] > mean_income).sum()\n",
    "low_income_count = (data['ApplicantIncome'] <= mean_income).sum()\n",
    "\n",
    "\n",
    "\n",
    "print('Applicants with Higher Income than mean:', high_income_count)\n",
    "print('Applicants with Lower Income than mean:', low_income_count)\n",
    "\n",
    "# Visualize income distribution\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(x=['High Income', 'Low Income'], y=[high_income_count, low_income_count], palette=[\"skyblue\", \"salmon\"])  \n",
    "plt.title('Income Distribution')\n",
    "plt.ylabel('Number of Applicants')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "sns.countplot(x=\"Self_Employed\", data=data, palette=[\"skyblue\", \"coral\", \"lightgreen\"])  \n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Self-Employed Status')\n",
    "plt.ylabel('Number of Applicants')\n",
    "plt.title('Distribution of Self-Employment')\n",
    "\n",
    "# Add count labels on top of the bars\n",
    "ax = plt.gca()\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.annotate(f'{height}', \n",
    "                xy=(p.get_x() + p.get_width() / 2, height), \n",
    "                ha='center', \n",
    "                va='bottom')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Create the count plot with a custom color palette\n",
    "sns.countplot(x=\"Credit_History\", data=data, palette=[\"skyblue\", \"orange\"]) \n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Credit History')\n",
    "plt.ylabel('Number of Applicants')\n",
    "plt.title('Distribution of Credit History')\n",
    "\n",
    "# Add count labels on top of the bars\n",
    "ax = plt.gca()\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.annotate(f'{height}', \n",
    "                xy=(p.get_x() + p.get_width() / 2, height), \n",
    "                ha='center', \n",
    "                va='bottom')\n",
    "\n",
    "# Adjust layout to prevent overlapping labels\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "sns.countplot(x=\"Property_Area\", data=data, palette=[\"skyblue\", \"orange\", \"green\"])  \n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Property Area')\n",
    "plt.ylabel('Number of Applicants')\n",
    "plt.title('Distribution of Property Areas')\n",
    "\n",
    "ax = plt.gca()\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.annotate(f'{height}', \n",
    "                xy=(p.get_x() + p.get_width() / 2, height), \n",
    "                ha='center', \n",
    "                va='bottom')\n",
    "\n",
    "# Adjust layout to prevent overlapping labels\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "sns.countplot(x=\"Loan_Amount_Term\", data=data, palette=\"viridis\")\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Loan Amount Term')\n",
    "plt.ylabel('Number of Applicants')\n",
    "plt.title('Distribution of Loan Amount Terms')\n",
    "\n",
    "# Add count labels on top of the bars\n",
    "ax = plt.gca()\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.annotate(f'{height}', \n",
    "                xy=(p.get_x() + p.get_width() / 2, height), \n",
    "                ha='center', \n",
    "                va='bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Create the count plot with a custom color palette\n",
    "sns.countplot(x=\"Loan_Status\", data=data, palette=[\"skyblue\", \"orange\"]) \n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Loan Status')\n",
    "plt.ylabel('Number of Applicants')\n",
    "plt.title('Distribution of Loan Statuses')\n",
    "\n",
    "# Add count labels on top of the bars\n",
    "ax = plt.gca()\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.annotate(f'{height}', \n",
    "                xy=(p.get_x() + p.get_width() / 2, height), \n",
    "                ha='center', \n",
    "                va='bottom')\n",
    "\n",
    "# Adjust layout to prevent overlapping labels\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "sns.countplot(x=\"Gender\", data=data, palette=[\"skyblue\", \"pink\"])  # Assuming two genders: Male and Female\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Number of Applicants')\n",
    "plt.title('Distribution of Genders')\n",
    "\n",
    "# Add count labels on top of the bars\n",
    "ax = plt.gca()\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.annotate(f'{height}', \n",
    "                xy=(p.get_x() + p.get_width() / 2, height), \n",
    "                ha='center', \n",
    "                va='bottom')\n",
    "\n",
    "# Adjust layout to prevent overlapping labels\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Define colors for the pie chart slices (adjust as needed)\n",
    "colors = sns.color_palette(\"pastel\")  # Using a pastel color palette\n",
    "\n",
    "# labels by descending order\n",
    "plt.pie(MarriedAnalysis, \n",
    "        labels=[(\"Married\"),(\"Single\"),(\"NaN\")], \n",
    "        startangle=140,  # Adjust start angle for better visual arrangement\n",
    "        autopct='%1.1f%%', \n",
    "        colors=colors)\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.title('Marital Status Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "sns.countplot(x=\"Dependents\", data=data, palette=[\"skyblue\", \"orange\", \"green\", \"red\", \"purple\"])\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Number of Dependents')\n",
    "plt.ylabel('Number of Applicants')\n",
    "plt.title('Distribution of Dependents')\n",
    "\n",
    "# Add count labels on top of the bars\n",
    "ax = plt.gca()\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.annotate(f'{height}', \n",
    "                xy=(p.get_x() + p.get_width() / 2, height), \n",
    "                ha='center', \n",
    "                va='bottom')\n",
    "\n",
    "# Adjust layout to prevent overlapping labels\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))  # Adjust figure size as needed\n",
    "\n",
    "# Define colors for the pie chart slices\n",
    "colors = sns.color_palette(\"pastel\")  # Using a pastel color palette \n",
    "\n",
    "# Plot the pie chart\n",
    "plt.pie(EducationAnalysis, labels=EducationAnalysis.index, autopct='%1.1f%%', startangle=140, colors=colors)\n",
    "\n",
    "# Add title\n",
    "plt.title('Distribution of Education Levels')\n",
    "\n",
    "# Equal aspect ratio ensures a circular pie chart\n",
    "plt.axis('equal') \n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Graph to analyse the outliers in the data for numerical values like applicant income, co-applicant income, loan amount\n",
    "\n",
    "def plot_distribution(data, column, title):\n",
    "    \"\"\"Plots the distribution of a numerical column using Matplotlib.\"\"\"\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.hist(data[column], bins=20, density=True, alpha=0.7)  # Adjust bins as needed\n",
    "    plt.title(title)\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Density')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_distribution(data, \"ApplicantIncome\", \"Applicant Income Distribution\")\n",
    "plot_distribution(loan_data, \"CoapplicantIncome\", \"Coapplicant Income Distribution\")\n",
    "plot_distribution(data, \"LoanAmount\", \"Loan Amount Distribution\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation Analysis\n",
    "It a statistical technique used to evaluate the relationship between two variables in a data set. The matrix is a table in which every cell contains a correlation coefficient, where 1 is considered a strong relationship between variables, 0 a neutral relationship and -1 a not strong relationship.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Calculates the correlation coefficients between all pairs of numerical variables in the dataset\n",
    "correlation_matrix = data.corr(numeric_only=True)\n",
    "\n",
    "plt.figure(figsize=(15, 7.5))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='flare') \n",
    "plt.title('Correlation Matrix')\n",
    "\n",
    "# Display the heatmap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is positive correlation between **Loan Amount** and **Applicant Income**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font size=\"4\" face=\"WildWest\">3. Data Relationships Analysis</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Create the contingency table \n",
    "contingency_table = pd.crosstab(data['Credit_History'], data['Loan_Status'])\n",
    "\n",
    "# Plot the contingency table using Seaborn's countplot (simpler than stacked barplot)\n",
    "sns.countplot(x='Credit_History', hue='Loan_Status', data=data)\n",
    "\n",
    "plt.xlabel('Credit History')\n",
    "plt.ylabel('Count of Applicants')\n",
    "plt.title('Relationship between Credit History and Loan Status')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis appears a **good credit history** significantly *increases the chances of loan approval*. Because the percentage of people who have a good credit history and are approved is much better than a bad credit history.\n",
    "\n",
    "Good credit History is directly proportional to chances of loan approval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "property_loan_table = pd.crosstab(data['Property_Area'], loan_data['Loan_Status'])\n",
    "sns.countplot(x='Property_Area', hue='Loan_Status', data=data)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Property Area')\n",
    "plt.ylabel('Count of Applicants')\n",
    "plt.title('Relationship between Property Area and Loan Status')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of loan that got accepted has property in **Semiurban** compared to *Urban* and *Rural*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Create a cross-tabulation of 'Gender' and 'Married' variables\n",
    "pd.crosstab(data.Gender, data.Married, dropna=True).plot(kind=\"bar\", figsize=(8, 4))\n",
    "\n",
    "\n",
    "# Add a title to the plot\n",
    "plt.title('Gender VS Married')\n",
    "\n",
    "# Label the x-axis\n",
    "plt.xlabel('Gender')\n",
    "\n",
    "# Label the y-axis\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Rotate the x-axis labels to avoid overlap\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most **male applicants** are already **married** compared to **female applicants**. Also, the number of **not married male applicants** are **higher** compare to **female applicants** that had **not married**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Create a cross-tabulation of 'Gender' and 'Loan Status' variables\n",
    "pd.crosstab(loan_data.Education, data.Loan_Status).plot(kind=\"bar\", figsize=(8, 5))\n",
    "\n",
    "# Add a title to the plot\n",
    "plt.title('Education Status VS Loan Status')\n",
    "\n",
    "# Label the x-axis\n",
    "plt.xlabel('Education')\n",
    "\n",
    "# Label the y-axis\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Rotate the x-axis labels to avoid overlap\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis appears a **graduate applicant** significantly increases the chances of *loan approval*. Because the percentage of people who graduated and were approved is much better than who didn't graduate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove Unneeded Features\n",
    "- Handling Missing Values\n",
    "- Encoding Categorical Variables\n",
    "- Handling Outliers\n",
    "- Handling Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font size=\"4\" face=\"WildWest\">1. Remove Unneeded Features</font>\n",
    "As Loan_ID is completely unique and not correlated with any of the other column, So we will drop it using .drop() function.\n",
    "- axis = 1 means column , axis = 0 means row.\n",
    "- inplace = True means the changes are reflected in the original DataFrame, inplace = False (default) means leaving the original DataFrame unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Dropping Loan_ID column\n",
    "data.drop(['Loan_ID'], axis = 1 , inplace = True)\n",
    "\n",
    "# Check the Loan_ID is dropped\n",
    "print(loan_data.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font size=\"4\" face=\"WildWest\">2. Handling Missing Values</font>\n",
    "\n",
    "**Missing values** are data points that are absent or not recorded for certain variables in a dataset. This can happen because of mistakes such as data entry errors, equipment failures, or simply because the information is not available.\n",
    "\n",
    " **How to detect missing values?**\n",
    " - Look for blank cells and use data analysis tools that can identify missing values like .isnull() functoin.\n",
    "\n",
    " **Decision options:**\n",
    "1. Keep them \n",
    "    - Not ideal, as missing values can lead to biased analyses and inaccurate predictions.\n",
    "2. Reassign new values to them (Using specific techniques)\n",
    "    - Imputation (Y):\n",
    "        - Replace missing values with estimated or calculated values based on the available data. This can be done using various methods such as:\n",
    "            1. **Mean/Median Imputation:** Replace with the average (mean) or middle value (median) for numerical data.\n",
    "            2. **Mode Imputation:** Replace with the most frequent value.\n",
    "    - Forward/Backward Fill (N):\n",
    "        - For time-series data, missing values can be filled with the last observed value (forward fill) or the next observed value (backward fill).\n",
    "    - Interpolation (N):\n",
    "        - Estimate missing values based on the trend or pattern observed in the existing data points.\n",
    "3. Delete them (Sometimes necessary, especially if missing values are extensive and cannot be reasonably imputed without introducing significant bias.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "null_counts = data.isnull().sum()\n",
    "\n",
    "# Display the number of null values\n",
    "print(null_counts)\n",
    "print(\"_________________________________________________________________\")\n",
    "print(colored(f\"Totally, there are {null_counts.sum()} null values in the dataset.\", attrs=['reverse']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\" face=\"WildWest\">There are two types of data:</font>\n",
    "- Numerical Data\n",
    "- Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Fill the missing values for numerical data, .fillna = fill (NaN) values\n",
    "'''\n",
    "## 1- Mean Imputation:\n",
    "loan_data[\"Credit_History\"] = loan_data[\"Credit_History\"].fillna(loan_data[\"Credit_History\"].mean())\n",
    "\n",
    "## 1- Median Imputation:\n",
    "loan_data[\"Credit_History\"] = loan_data[\"Credit_History\"].fillna(loan_data[\"Credit_History\"].median())\n",
    "'''\n",
    "\n",
    "## 2- Mode Imputatoin:\n",
    "# The best way fill in the Credit History is the mode (Most common valus)\n",
    "# [0] This ensures that if there are multiple mode values, only the first one is selected.\n",
    "loan_data[\"Credit_History\"] = loan_data[\"Credit_History\"].fillna(loan_data[\"Credit_History\"].mode()[0])\n",
    "\n",
    "'''\n",
    "## 3- Forward Fill\n",
    "loan_data[\"Credit_History\"] = loan_data[\"Credit_History\"].fillna(method='ffill')\n",
    "\n",
    "## 3- Backward Fill\n",
    "loan_data[\"Credit_History\"] = loan_data[\"Credit_History\"].fillna(method='bfill')\n",
    "\n",
    "## 4- Interpolation\n",
    "loan_data[\"Credit_History\"] = loan_data[\"Credit_History\"].interpolate(method='linear') \n",
    "'''\n",
    "############################################################################################\n",
    "\n",
    "## 1- Mean Imputation:\n",
    "# The best way fill in the Loan Amount is the Mean (The average).\n",
    "loan_data[\"LoanAmount\"] = loan_data[\"LoanAmount\"].fillna(loan_data[\"LoanAmount\"].mean())\n",
    "\n",
    "'''\n",
    "## 1- Median Imputation:\n",
    "loan_data[\"LoanAmount\"] = loan_data[\"LoanAmount\"].fillna(loan_data[\"LoanAmount\"].median())\n",
    "\n",
    "\n",
    "## 2- Mode Imputatoin:\n",
    "loan_data[\"LoanAmount\"] = loan_data[\"LoanAmount\"].fillna(loan_data[\"LoanAmount\"].mode()[0])\n",
    "'''\n",
    "############################################################################################\n",
    "'''\n",
    "## 1- Mean Imputation:\n",
    "loan_data[\"Loan_Amount_Term\"] = loan_data[\"Loan_Amount_Term\"].fillna(loan_data[\"Loan_Amount_Term\"].mean())\n",
    "\n",
    "## 1- Median Imputation:\n",
    "loan_data[\"Loan_Amount_Term\"] = loan_data[\"Loan_Amount_Term\"].fillna(loan_data[\"Loan_Amount_Term\"].median())\n",
    "'''\n",
    "\n",
    "## 2- Mode Imputatoin:\n",
    "# The best way fill in the Credit History is the mode (Most common valus)\n",
    "loan_data[\"Loan_Amount_Term\"] = loan_data[\"Loan_Amount_Term\"].fillna(loan_data[\"Loan_Amount_Term\"].mode()[0])\n",
    "\n",
    "############################################################################################\n",
    "\n",
    "# Fill the missing values for categorical data.\n",
    "loan_data[\"Gender\"] = loan_data[\"Gender\"].fillna(loan_data[\"Gender\"].mode()[0])\n",
    "loan_data[\"Married\"] = loan_data[\"Married\"].fillna(loan_data[\"Married\"].mode()[0])\n",
    "loan_data[\"Dependents\"] = loan_data[\"Dependents\"].fillna(loan_data[\"Dependents\"].mode()[0])\n",
    "loan_data[\"Self_Employed\"] = loan_data[\"Self_Employed\"].fillna(loan_data[\"Self_Employed\"].mode()[0])\n",
    "\n",
    "\n",
    "# Delete them (but it is not the best choose for me [Low accuracy] )\n",
    "# loan_data = loan_data.dropna(subset=['Gender', 'Married', 'Dependents', 'Self_Employed', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Check for missing values after handling\n",
    "null_counts = loan_data.isnull().sum()\n",
    "\n",
    "# Display the number of null values after handling\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font size=\"4\" face=\"WildWest\">3. Encoding Categorical Variables</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Convert categorical variables into dummy/indicator variables through a process called \"one-hot\" encoding\n",
    "loan_data = pd.get_dummies(loan_data)\n",
    "\n",
    "# Drop unneeded features\n",
    "loan_data = loan_data.drop(['Gender_Female', \n",
    "                            'Married_No', \n",
    "                            'Education_Not Graduate',\n",
    "                            'Self_Employed_No', \n",
    "                            'Loan_Status_N'], axis = 1) # axis = 1 for column\n",
    "\n",
    "# Rename existing columns\n",
    "newColunmsNames = {'Gender_Male': 'Gender', \n",
    "                   'Married_Yes': 'Married', \n",
    "                   'Education_Graduate': 'Education', \n",
    "                   'Self_Employed_Yes': 'Self_Employed',\n",
    "                   'Loan_Status_Y': 'Loan_Status'}\n",
    "\n",
    "# Assigning new columns names\n",
    "loan_data.rename(columns=newColunmsNames, inplace=True)\n",
    "\n",
    "# Display the columns names and shape of the transformed dataset\n",
    "## Get the column names of the DataFrame\n",
    "column_names = loan_data.columns.tolist()\n",
    "\n",
    "## Print the column names in a readable format\n",
    "print(colored(\"Column Names:\", \"blue\",attrs=['reverse']))\n",
    "\n",
    "for col in column_names:\n",
    "    print(f\"- {col}\")\n",
    "    \n",
    "print(\"The shape =\",loan_data.shape)\n",
    "print(\"_______________________________________________\")\n",
    "\n",
    "# Display the first 5 rows of the transformed target variable\n",
    "print(colored(\"Transformed Target Variable (Y):\",\"blue\", attrs=['reverse']))\n",
    "print(loan_data['Loan_Status'].head())  # First 5 rows by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font size=\"4\" face=\"WildWest\">4. Handling Outliers</font>\n",
    "\n",
    "**Outliers** are data points that significantly differ from the rest of the observations in a dataset, often due to errors in data collection or genuine extreme values.\n",
    "\n",
    " **How to detect outliers?**\n",
    "- Visualization data (Numerical values)\n",
    "\n",
    " **Decision options:**\n",
    "1. Keep them (Not the best solution, I try it and not get high accuracy, \"There is better\")\n",
    "2. Reassign new values to them (Using specific techniques)\n",
    "    - Capping Outliers (N)\n",
    "        - Instead of removing outliers entirely, replace extreme values with more reasonable thresholds.\n",
    "    - Robust Scaling (Y)\n",
    "        - Use scaling methods less sensitive to outliers (e.g., IQR scaling, standardization with robust estimators).\n",
    "            - Robust Scaling Function\n",
    "            - IQR scaling\n",
    "    - Replace with mean (N)\n",
    "        - Replacing the outliers with the mean value\n",
    "3. Delete them (N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing outliers in this process before making any handling, but in another graph than the previous graph I used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Set the figure size\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Only variables that have outliers\n",
    "outliersColumns = loan_data.get([\"ApplicantIncome\", \"CoapplicantIncome\", \"LoanAmount\", \"Loan_Amount_Term\"])\n",
    "\n",
    "# Add outliers to the plot\n",
    "sns.stripplot(data=outliersColumns, color=\"red\", jitter=0.3, size=5)\n",
    "\n",
    "# Set the axis labels and title\n",
    "plt.title(\"Outliers\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Process**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Reassign new values to them\n",
    "\n",
    "'''\n",
    "# 1- Capping Outliers\n",
    "loan_data.loc[loan_data['ApplicantIncome'] > 20000, 'ApplicantIncome'] = 20000\n",
    "loan_data.loc[loan_data['CoapplicantIncome'] > 10000, 'CoapplicantIncome'] = 10000\n",
    "'''\n",
    "'''\n",
    "# 2- Robust Scaling\n",
    "## Method 1\n",
    "\n",
    "# import Robust Scaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "loan_data[['ApplicantIncome', 'CoapplicantIncome']] = scaler.fit_transform(loan_data[['ApplicantIncome', 'CoapplicantIncome']])\n",
    "\n",
    "## Method 2\n",
    "\n",
    "# IQR Scaling\n",
    "Q1 = loan_data.quantile(0.25)\n",
    "Q3 = loan_data.quantile(0.75)\n",
    "\n",
    "# Calcuate the Interquartile Range (IQR)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Removing Qutliers\n",
    "loan_data = loan_data[~((loan_data < (Q1 - 1.5 * IQR)) |(loan_data > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "# 3- Replace with mean\n",
    "loan_data.loc[loan_data['ApplicantIncome'] > 20000, 'ApplicantIncome'] = loan_data['ApplicantIncome'].mean()\n",
    "loan_data.loc[loan_data['CoapplicantIncome'] > 10000, 'CoapplicantIncome'] = loan_data['CoapplicantIncome'].mean()\n",
    "'''\n",
    "'''\n",
    "# Delete the outliers\n",
    "# The data before deleting outliers \n",
    "print(\"Before Removing the outliers\", loan_data.shape)\n",
    "\n",
    "# Deleting outliers (Removing the number of observation where the applicant income is more than 20k)\n",
    "loan_data = loan_data[loan_data['ApplicantIncome']<20000]\n",
    "\n",
    "# Deleting outliers (Removing the number of observation where the co-applicant income is more than 10k)\n",
    "loan_data = loan_data[loan_data['CoapplicantIncome']<10000]\n",
    "\n",
    "#The data after deleting outliers\n",
    "print(\"After Removing the outliers\", loan_data.shape)\n",
    "'''\n",
    "## Method 2\n",
    "\n",
    "# IQR Scaling\n",
    "Q1 = loan_data.astype(np.float32).quantile(0.25)\n",
    "Q3 = loan_data.astype(np.float32).quantile(0.75)\n",
    "\n",
    "# Calcuate the Interquartile Range (IQR)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Removing Qutliers\n",
    "loan_data = loan_data[~((loan_data < (Q1 - 1.5 * IQR)) |(loan_data > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "# printing shape\n",
    "print(loan_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Square Root Transformation - to normalized the distribution.\n",
    "loan_data.ApplicantIncome = np.sqrt(loan_data.ApplicantIncome)\n",
    "loan_data.CoapplicantIncome = np.sqrt(loan_data.CoapplicantIncome)\n",
    "loan_data.LoanAmount = np.sqrt(loan_data.LoanAmount)\n",
    "\n",
    "print(loan_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize data distribution after handling outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Set the figure size\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Only variables that have outliers\n",
    "outliersColumns = loan_data.get([\"ApplicantIncome\", \"CoapplicantIncome\", \"LoanAmount\", \"Loan_Amount_Term\"])\n",
    "\n",
    "# Add outliers to the plot\n",
    "sns.stripplot(data=outliersColumns, color=\"red\", jitter=0.3, size=5)\n",
    "\n",
    "# Set the axis labels and title\n",
    "plt.title(\"Outliers\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another Graphe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Histogram distribution for numerical values\n",
    "\n",
    "# Set the seaborn theme palette\n",
    "sns.set_theme(palette=\"flare\")\n",
    "\n",
    "def plot_distribution(column, title):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.histplot(data=loan_data, x=column, kde=True)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "# Plot distribution for each numerical column\n",
    "plot_distribution(\"ApplicantIncome\", \"Applicant Income Distribution\")\n",
    "plot_distribution(\"CoapplicantIncome\", \"Coapplicant Income Distribution\")\n",
    "plot_distribution(\"LoanAmount\", \"Loan Amount Distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the distribution after using log transformation are much better compared to original distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font size=\"4\" face=\"WildWest\">5. Handling Duplicates</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# List of column names to check for duplicates (Numerical values)\n",
    "columns_to_check = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History']\n",
    "\n",
    "# Iterate over each column name\n",
    "for column_name in columns_to_check:\n",
    "    # Checking for duplicate entries in the current column\n",
    "    duplicate_count = loan_data[column_name].duplicated().sum()\n",
    "    \n",
    "    # Output the result with a descriptive message\n",
    "    if duplicate_count == 0:\n",
    "        print(colored(f\"No duplicate entries found in the {column_name} column.\", \"green\", attrs=['reverse']))\n",
    "    else:\n",
    "        print(colored(f\"Number of duplicate entries found in the {column_name} column: {duplicate_count}\", \"cyan\", attrs=['bold']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We don't need to handle duplicate values because it isn't affecting the accuracy or integrity of the analysis or model being performed.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Processing\n",
    "It involves *preparing* and *transforming raw data* into a suitable format for analysis and **model training**. Effective data processing ensures that the machine learning algorithms can extract meaningful patterns and make accurate predictions, includes:\n",
    "- Splitting data into \"Features\" - \"Target\"\n",
    "- SMOTE Technique\n",
    "- Data Re-scaling and Normalizing the features\n",
    "- Splitting data into \"Training\" - \"Testing\" Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font size=\"4\" face=\"WildWest\">1. Splitting data into \"Features\" - \"Target\"</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Features \"Inputs\" (X)\n",
    "X = loan_data.drop(columns=['Loan_Status'])\n",
    "\n",
    "# Target variable \"Outputs\" (Y)\n",
    "Y = loan_data['Loan_Status']\n",
    "\n",
    "# Print the shapes of X and Y to verify the splitting\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of Y:\", Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font size=\"4\" face=\"WildWest\">2. SMOTE Technique</font>\n",
    "In previous exploration, it can be seen that the number between **accepted** and **rejected** loan is *imbalanced*. In this section, oversampling technique will be used to avoid overfitting. But recently I discovered that not using it will give higher accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font size=\"4\" face=\"WildWest\">3. Data Re-scaling and Normalizing the features</font>\n",
    "***Min-Max Scaling:*** transforms the features so that they fall within a specified range, typically between 0 and 1.\n",
    "\n",
    "***Standardization:*** the features so that they have a mean of 0 , typically between -1 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Rescale and normalize the features\n",
    "'''\n",
    "# Standardization (Normalization)\n",
    "standard_scaler = StandardScaler()\n",
    "X = standard_scaler.fit_transform(X)\n",
    "'''\n",
    "\n",
    "# Min-Max Scaling (Rescaling)\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "\n",
    "#I will choose one of them in the future part \"model selection\" based on the highest accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why we use fit_transform() on training data but transform() on the test data?**\n",
    "    \n",
    "The fit_transform() method is used on training data to calculate scaling parameters like **mean** and **standard deviation**, then applies scaling. For test data, we apply the same scaling transformation without recalculating parameters, ensuring consistency for fair comparison and accurate evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font size=\"4\" face=\"WildWest\">4. Splitting data into \"Training\" - \"Testing\" Data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "# X: Features, Y: Target variable\n",
    "# test_size=0.2 specifies that 20% of the data will be used for testing and 80% for training\n",
    "# random_state=0 sets the random seed for reproducibility\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Print the shapes of the training and testing sets to verify the splitting\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of Y_train:\", Y_train.shape)\n",
    "print(\"Shape of Y_test:\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Selection\n",
    "Model selection is an essential step in machine learning that involves choosing **the most appropriate model for a given problem**. The goal of model selection is to find a model that generalizes well to unseen data and provides the best performance on the task at hand.\n",
    "- Importing models for selection process\n",
    "- Training our models.\n",
    "    1. Decision Tree Classifier\n",
    "    2. Random Forest Classifier (Highest Accuracy) \n",
    "    3. Naives Bayes\n",
    "        - GaussianNB (Suitable for continuous data)\n",
    "        - BernoulliNB (Suitable for binary value)\n",
    "    4. Logistic Regression \n",
    "    5. Ridge Classifier CV\n",
    "    6. K-Nearest Neighbors (KNN)\n",
    "- For future searching\n",
    "    7. Support Vector Classifier\n",
    "    8. Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font size=\"4\" face=\"WildWest\">1. Importing models for selection process</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier  # For Decision Tree Classifier Model\n",
    "from sklearn.ensemble import RandomForestClassifier # For Random Forest Classifier Model\n",
    "from sklearn.neighbors import KNeighborsClassifier # For K-Nearest Neighbors Model\n",
    "from sklearn.naive_bayes import GaussianNB,BernoulliNB  # For Gaussian,Bernoulli Naive Bayes Classifier Model\n",
    "from sklearn.linear_model import RidgeClassifierCV, LogisticRegression # For Ridge Classifier Cross-validated and Logistic Regression Models\n",
    "from sklearn.svm import SVC  # For Support Vector Classifier Model\n",
    "from sklearn.ensemble import GradientBoostingClassifier  # For Gradient Boosting Classifier Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font size=\"4\" face=\"WildWest\">2. Training the Machine Learning Algorithms</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier Parameters\n",
    "'''\n",
    "sklearn.tree.DecisionTreeClassifier(*, criterion='gini', \n",
    "                                    splitter='best', max_depth=None, \n",
    "                                    min_samples_split=2, min_samples_leaf=1, \n",
    "                                    min_weight_fraction_leaf=0.0, max_features=None, \n",
    "                                    random_state=None, max_leaf_nodes=None, \n",
    "                                    min_impurity_decrease=0.0, class_weight=None, \n",
    "                                    ccp_alpha=0.0, monotonic_cst=None)\n",
    "'''\n",
    "\n",
    "# max_depth (The maximum depth of the tree \"       \")\n",
    "# min_samples_split (The minimum number of samples required to split an internal node \"2 by default\")\n",
    "# min_samples_leaf (The minimum number of samples required to be at a leaf node)\n",
    "# max_features (The number of features to consider when looking for the best split)\n",
    "\n",
    "# Initialize lists to store training and testing accuracies\n",
    "scoreListDT_Train = []\n",
    "scoreListDT_Test = []\n",
    "\n",
    "# Iterate over different values of max_depth\n",
    "for i in range(1, 20):\n",
    "    # Iterate over different values of min_samples_leaf\n",
    "    for j in range(1, 5):\n",
    "        # Create a Decision Tree model with the different values of max_depth, min_samples_leaf, and fixed max_features\n",
    "        Model1 = DecisionTreeClassifier(max_depth=i, min_samples_leaf=j, max_features=2)\n",
    "\n",
    "        # Fit the model on the training data\n",
    "        Model1.fit(X_train, Y_train)\n",
    "\n",
    "        # Calculate and store the training accuracy\n",
    "        scoreListDT_Train.append(Model1.score(X_train, Y_train))\n",
    "\n",
    "        # Calculate and store the testing accuracy\n",
    "        scoreListDT_Test.append(Model1.score(X_test, Y_test))\n",
    "\n",
    "# Find the maximum accuracy for both training and testing\n",
    "DT_Accuracy_Train = max(scoreListDT_Train) \n",
    "DT_Accuracy_Test = max(scoreListDT_Test)\n",
    "\n",
    "# Print the best accuracies achieved\n",
    "print(f\"Decision Tree best accuracy (Training): {DT_Accuracy_Train*100:.2f}%\")\n",
    "print(f\"Decision Tree best accuracy (Testing): {DT_Accuracy_Test*100:.2f}%\")\n",
    "\n",
    "# Print a success message indicating that the model has been trained successfully\n",
    "print(colored(\"The Decision Tree model has been trained successfully\",\"green\", attrs=['reverse']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier Parameters\n",
    "'''\n",
    "sklearn.ensemble.RandomForestClassifier(n_estimators=100, *, criterion='gini', \n",
    "                                        max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "                                        min_weight_fraction_leaf=0.0, max_features='sqrt', max_leaf_nodes=None, \n",
    "                                        min_impurity_decrease=0.0, bootstrap=True, oob_score=False, \n",
    "                                        n_jobs=None, random_state=None, verbose=0, \n",
    "                                        warm_start=False, class_weight=None, ccp_alpha=0.0, \n",
    "                                        max_samples=None, monotonic_cst=None)\n",
    "'''\n",
    "\n",
    "# n_estimators (The number of trees in the forest\"   \")\n",
    "# max_depth (The maximum depth of the tree.)\n",
    "# random_state (Controls both the randomness of the bootstrapping of the samples used when building trees)\n",
    "\n",
    "# Initialize lists to store training and testing accuracies\n",
    "scoreListRF_Train = []\n",
    "scoreListRF_Test = []\n",
    "\n",
    "'''\n",
    "max_dep      ----------> (1, 5),(1, 10) \n",
    "rand_state   ----------> (1, 35),(1, 50)\n",
    "n_est        ----------> (1, 30),(1, 30)\n",
    "'''\n",
    "\n",
    "# Iterate over different values of max_depth\n",
    "for max_dep in range(1, 10):\n",
    "    # Iterate over different values of random_state\n",
    "    for rand_state in range(1, 50):\n",
    "        # Iterate over different values of n_estimators\n",
    "        for n_est in range(1, 30):\n",
    "            # Create a Random Forest model with the different values of max_depth, random_state, and n_estimators\n",
    "            Model2 = RandomForestClassifier(n_estimators=n_est, random_state=rand_state, max_depth=max_dep)            \n",
    "            \n",
    "            # Fit the model on the training data\n",
    "            Model2.fit(X_train, Y_train)\n",
    "            \n",
    "            # Calculate and store the training accuracy\n",
    "            scoreListRF_Train.append(Model2.score(X_train, Y_train))\n",
    "            \n",
    "            # Calculate and store the testing accuracy\n",
    "            scoreListRF_Test.append(Model2.score(X_test, Y_test))\n",
    "\n",
    "# Find the maximum accuracy for both training and testing\n",
    "RF_Accuracy_Train = max(scoreListRF_Train) \n",
    "RF_Accuracy_Test = max(scoreListRF_Test)\n",
    "\n",
    "# Print the best accuracies achieved\n",
    "print(f\"Random Forest best accuracy (Training): {RF_Accuracy_Train*100:.2f}%\")\n",
    "print(f\"Random Forest best accuracy (Testing): {RF_Accuracy_Test*100:.2f}%\")\n",
    "\n",
    "# Print a success message indicating that the model has been trained successfully\n",
    "print(colored(\"The Random Forest model has been trained successfully\",\"green\", attrs=['reverse']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes Parameters\n",
    "'''\n",
    "sklearn.naive_bayes.GaussianNB(*, priors=None, var_smoothing=1e-09)\n",
    "'''\n",
    "\n",
    "# var_smoothing (Portion of the largest variance of all features that is added to variances for calculation stability.)\n",
    "\n",
    "# Initialize lists to store training and testing accuracies\n",
    "scoreListGNB_Train = []\n",
    "scoreListGNB_Test = []\n",
    "\n",
    "# Iterate over different values of var_smoothing\n",
    "for i in range(1, 9):\n",
    "    # Create a Gaussion Naive Bayes Model with the different values of var_smoothing\n",
    "    Model3_1 = GaussianNB(var_smoothing=10**(-i))\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    Model3_1.fit(X_train, Y_train)\n",
    "    \n",
    "    # Calculate and store the training accuracy\n",
    "    scoreListGNB_Train.append(Model3_1.score(X_train, Y_train))\n",
    "    \n",
    "    # Calculate and store the testing accuracy\n",
    "    scoreListGNB_Test.append(Model3_1.score(X_test, Y_test))\n",
    "\n",
    "# Find the maximum accuracy for both training and testing\n",
    "GNB_Accuracy_Train = max(scoreListGNB_Train) \n",
    "GNB_Accuracy_Test = max(scoreListGNB_Test)\n",
    "\n",
    "# Print the best accuracies achieved\n",
    "print(f\"Gaussian Naive Bayes best accuracy (Training): {GNB_Accuracy_Train*100:.2f}%\")\n",
    "print(f\"Gaussian Naive Bayes best accuracy (Testing): {GNB_Accuracy_Test*100:.2f}%\")\n",
    "\n",
    "# Print a success message indicating that the model has been trained successfully\n",
    "print(colored(\"The Gaussian Naive Bayes model has been trained successfully\",\"green\", attrs=['reverse']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Bernoulli Naive Bayes Parameters\n",
    "'''\n",
    "sklearn.naive_bayes.BernoulliNB(*, alpha=1.0, force_alpha=True, binarize=0.0, fit_prior=True, class_prior=None)\n",
    "'''\n",
    "\n",
    "# alpha (Additive (Laplace/Lidstone) smoothing parameter)\n",
    "# force_alpha (If False and alpha is close to zero, it's adjusted to 1e-10 to prevent numerical errors; otherwise, alpha stays unchanged.)\n",
    "# binarize (Sets the threshold for converting sample features to binary values; if None, assumes the input is already binary.)\n",
    "\n",
    "# Create a Bernoulli Naive Bayes Model\n",
    "Model3_2= BernoulliNB()\n",
    "\n",
    "# Fit the model on the training data\n",
    "Model3_2.fit(X_train, Y_train)\n",
    "    \n",
    "# Calculate and store the training accuracy\n",
    "BNB_Accuracy_Train = Model3_2.score(X_train, Y_train)\n",
    "    \n",
    "# Calculate and store the testing accuracy\n",
    "BNB_Accuracy_Test = Model3_2.score(X_test, Y_test)\n",
    "\n",
    "# Print the best accuracies achieved\n",
    "print(f\"Bernoulli Naive Bayes best accuracy (Training): {BNB_Accuracy_Train*100:.2f}%\")\n",
    "print(f\"Bernoulli Naive Bayes best accuracy (Testing): {BNB_Accuracy_Test*100:.2f}%\")\n",
    "\n",
    "# Print a success message indicating that the model has been trained successfully\n",
    "print(colored(\"The Bernoulli Naive Bayes model has been trained successfully\",\"green\", attrs=['reverse']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Logistic Regression Parameters\n",
    "'''\n",
    "sklearn.linear_model.LogisticRegression(penalty='l2', *, \n",
    "                                        dual=False, tol=0.0001, \n",
    "                                        C=1.0, fit_intercept=True, \n",
    "                                        intercept_scaling=1, class_weight=None, \n",
    "                                        random_state=None, solver='lbfgs', \n",
    "                                        max_iter=100, multi_class='auto', \n",
    "                                        verbose=0, warm_start=False, \n",
    "                                        n_jobs=None, l1_ratio=None)\n",
    "'''\n",
    "\n",
    "# tol (\"     \")\n",
    "# C (\"        ,    \")\n",
    "# solver (\" \")\n",
    "# max_iter (\"  \")\n",
    "# random_state (\"    \")\n",
    "# n_jobs (\"   ,   1  ,       \")\n",
    "\n",
    "'''\n",
    "solver:\n",
    "liblinear : small data\n",
    "sag       : big data\n",
    "sage      : big data\n",
    "\n",
    "'''\n",
    "\n",
    "# Initialize lists to store training and testing accuracies\n",
    "scoreListLR_Train = []\n",
    "scoreListLR_Test = []\n",
    "\n",
    "# Iterate over different values of random_state\n",
    "for i in range(1, 150):\n",
    "    # Iterate over different values of max_iter\n",
    "    for j in range(1, 10):\n",
    "        # Create a Logistic Regression Model with the different values of random_state and max_iter\n",
    "        Model4= LogisticRegression(random_state=i, solver='saga', max_iter=j)\n",
    "\n",
    "        # Fit the model on the training data\n",
    "        Model4.fit(X_train,Y_train)\n",
    "\n",
    "        # Calculate and store the training accuracy\n",
    "        scoreListLR_Train.append(Model4.score(X_train, Y_train))\n",
    "\n",
    "        # Calculate and store the testing accuracy\n",
    "        scoreListLR_Test.append(Model4.score(X_test, Y_test))\n",
    "\n",
    "# Find the maximum accuracy for both training and testing\n",
    "LR_Accuracy_Train = max(scoreListLR_Train) \n",
    "LR_Accuracy_Test = max(scoreListLR_Test)\n",
    "\n",
    "# Print the best accuracies achieved\n",
    "print(f\"Logistic Regression best accuracy (Training): {LR_Accuracy_Train*100:.2f}%\")\n",
    "print(f\"Logistic Regression best accuracy (Testing): {LR_Accuracy_Test*100:.2f}%\")\n",
    "\n",
    "# Print a success message indicating that the model has been trained successfully\n",
    "print(colored(\"The Logistic Regression model has been trained successfully\",\"green\", attrs=['reverse']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ridge Classifier CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Ridge Classifier CV Parameters\n",
    "'''\n",
    "sklearn.linear_model.RidgeClassifierCV(alphas=(0.1, 1.0, 10.0), *, \n",
    "                                       fit_intercept=True, scoring=None, \n",
    "                                       cv=None, class_weight=None, \n",
    "                                       store_cv_values=False)\n",
    "'''\n",
    "# alphas (Array of alpha values to try. Regularization strength)\n",
    "# cv (Determines the cross-validation splitting strategy.)\n",
    "\n",
    "# Create a Ridge Classifier Model\n",
    "Model5= RidgeClassifierCV()\n",
    "\n",
    "# Fit the model on the training data\n",
    "Model5.fit(X_train,Y_train)\n",
    "\n",
    "# Calculate and store the training accuracy\n",
    "RCCV_Accuracy_Train = Model5.score(X_train, Y_train)\n",
    "\n",
    "# Calculate and store the testing accuracy\n",
    "RCCV_Accuracy_Test = Model5.score(X_test, Y_test)\n",
    "\n",
    "# Print the best accuracies achieved\n",
    "print(f\"Ridge Classifier CV best accuracy (Training): {RCCV_Accuracy_Train*100:.2f}%\")\n",
    "print(f\"Ridge Classifier CV best accuracy (Testing): {RCCV_Accuracy_Test*100:.2f}%\")\n",
    "\n",
    "# Print a success message indicating that the model has been trained successfully\n",
    "print(colored(\"The Ridge Classifier CV model has been trained successfully\",\"green\", attrs=['reverse']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- K-Nearest Neighbors (KNN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbors (KNN) Parameters\n",
    "'''\n",
    "sklearn.neighbors.KNeighborsClassifier(n_neighbors=5, *, \n",
    "                                       weights='uniform', algorithm='auto', \n",
    "                                       leaf_size=30, p=2, \n",
    "                                       metric='minkowski', \n",
    "                                       metric_params=None, n_jobs=None)\n",
    "'''\n",
    "\n",
    "# n_neighbors (Number of neighbors to use by default for kneighbors queries.)\n",
    "# metric (Metric to use for distance computation.)\n",
    "# n_jobs (The number of parallel jobs to run for neighbors search.)\n",
    "\n",
    "# Initialize lists to store training and testing accuracies\n",
    "scoreListknn_Train = []\n",
    "scoreListknn_Test = []\n",
    "\n",
    "# Iterate over different values of n_neighbors\n",
    "for i in range(3, 16):\n",
    "    # Create a KNN model with the different value of n_neighbors\n",
    "    Model6 = KNeighborsClassifier(n_neighbors=i, weights='distance')\n",
    "    \n",
    "    # Fit the model on the training data\n",
    "    Model6.fit(X_train, Y_train)\n",
    "    \n",
    "    # Calculate and store the training accuracy\n",
    "    scoreListknn_Train.append(Model6.score(X_train, Y_train))\n",
    "    \n",
    "    # Calculate and store the testing accuracy\n",
    "    scoreListknn_Test.append(Model6.score(X_test, Y_test))\n",
    "\n",
    "# Plot the training accuracy for different values of n_neighbors\n",
    "plt.plot(range(3, 16), scoreListknn_Train)\n",
    "plt.xticks(np.arange(3, 16, 1))\n",
    "plt.title(\"Training Accuracy vs K value\")\n",
    "plt.xlabel(\"K value\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "# Plot the testing accuracy for different values of n_neighbors\n",
    "plt.plot(range(3, 16), scoreListknn_Test)\n",
    "plt.xticks(np.arange(3, 16, 1))\n",
    "plt.title(\"Testing Accuracy vs K value\")\n",
    "plt.xlabel(\"K value\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "# Find the maximum accuracy for both training and testing\n",
    "KNN_Accuracy_Train = max(scoreListknn_Train) \n",
    "KNN_Accuracy_Test = max(scoreListknn_Test)\n",
    "\n",
    "# Print the best accuracies achieved\n",
    "print(f\"KNN best accuracy (Training): {KNN_Accuracy_Train*100:.2f}%\")\n",
    "print(f\"KNN best accuracy (Testing): {KNN_Accuracy_Test*100:.2f}%\")\n",
    "\n",
    "# Print a success message indicating that the model has been trained successfully\n",
    "print(colored(\"The K-Nearest Neighbors (KNN) model has been trained successfully\",\"green\", attrs=['reverse']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation\n",
    "- Training Score\n",
    "- Testing Score.\n",
    "- Choosing the better Model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font size=\"4\" face=\"WildWest\">1. Training Score</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Dictionary to store model names and their respective training scores (key:value)\n",
    "model_train_scores = {\n",
    "    \"Model 1-Decision Tree Classifier\": DT_Accuracy_Train,\n",
    "    \"Model 2-Random Forest Classifier\": RF_Accuracy_Train,\n",
    "    \"Model 3-GaussianNB\": GNB_Accuracy_Train,\n",
    "    \"Model 3-BernoulliNB\": BNB_Accuracy_Train,\n",
    "    \"Model 4-Logistic Regression\": LR_Accuracy_Train,\n",
    "    \"Model 5-Ridge Classifier CV\": RCCV_Accuracy_Train,\n",
    "    \"Model 6-K-Nearest Neighbors (KNN)\": KNN_Accuracy_Train\n",
    "}\n",
    "\n",
    "# Loop through each model and print the training score\n",
    "for model_name, accuracy in model_train_scores.items():\n",
    "    print(colored(f\"{model_name:<50} Training Score: {accuracy*100}\", \"green\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font size=\"4\" face=\"WildWest\">2. Testing Score</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Dictionary to store model names and their respective testing scores\n",
    "model_test_scores = {\n",
    "    \"Model 1-Decision Tree Classifier\": DT_Accuracy_Test,\n",
    "    \"Model 2-Random Forest Classifier\": RF_Accuracy_Test,\n",
    "    \"Model 3-GaussianNB\": GNB_Accuracy_Test,\n",
    "    \"Model 3-BernoulliNB\": BNB_Accuracy_Test,\n",
    "    \"Model 4-Logistic Regression\": LR_Accuracy_Test,\n",
    "    \"Model 5-Ridge Classifier CV\": RCCV_Accuracy_Test,\n",
    "    \"Model 6-K-Nearest Neighbors (KNN)\": KNN_Accuracy_Test\n",
    "}\n",
    "\n",
    "# Loop through each model and print the testing score\n",
    "for model_name, accuracy in model_test_scores.items():\n",
    "    print(colored(f\"{model_name:<50} Testing Score: {accuracy*100}\", \"green\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font size=\"4\" face=\"WildWest\">3. Choosing the better Model.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best models in accuracy are models 1 & 2 & 4 : **Decision Tree Classifier** and **Random Forest Classifier** and **Logistic Regression** with accuracy **96.43%**. Which we can choose any one of them for our *deployment*. I have chosen **Random Forest Classifier** model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#4863A0\"> Model Deployment </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# File mode explanation:\n",
    "# 'r'  - open for reading (default)\n",
    "# 'w'  - open for writing, truncating the file first\n",
    "# 'x'  - create a new file and open it for writing\n",
    "# 'a'  - open for writing, appending to the end of the file if it exists\n",
    "# 'b'  - binary mode\n",
    "# 't'  - text mode (default)\n",
    "# '+'  - open a disk file for updating (reading and writing)\n",
    "# 'U'  - universal newline mode (deprecated)\n",
    "\n",
    "# Define the filename for the pickle file\n",
    "filename = 'model.pkl'\n",
    "\n",
    "# Save (serialize) the model to the file using pickle\n",
    "# 'wb' mode opens the file in binary format for writing\n",
    "pickle.dump(\"Model 1\", open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 15953,
     "sourceId": 21070,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 74581,
     "sourceId": 169310,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 91803,
     "sourceId": 213142,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 137197,
     "sourceId": 325031,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 228063,
     "sourceId": 488290,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 756433,
     "sourceId": 1316934,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 831855,
     "sourceId": 1420931,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2637478,
     "sourceId": 4512631,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3378270,
     "sourceId": 5877232,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4436641,
     "sourceId": 7617627,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
